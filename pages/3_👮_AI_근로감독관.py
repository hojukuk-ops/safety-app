import streamlit as st
import google.generativeai as genai

# [ì£¼ì˜] st.set_page_configëŠ” app.pyì—ì„œ ì„¤ì •í•˜ë¯€ë¡œ ìƒëµ

# API í‚¤ ì„¤ì •
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except:
    st.error("ğŸš¨ API í‚¤ ì˜¤ë¥˜: secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# í—¤ë”: AI ê·¼ë¡œê°ë…ê´€ í˜ë¥´ì†Œë‚˜ ì„¤ì •
# ==========================================
st.title("ğŸ‘® ì•ˆì‚°ë„ì‹œê³µì‚¬ AI ê·¼ë¡œê°ë…ê´€ (ì±—ë´‡)")
st.info("ì‚°ì—…ì•ˆì „ë³´ê±´ë²•, ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²• ë“± ë³µì¡í•œ ë²•ë ¹ê³¼ ì‘ì—…ì „ ì ê²€ì‚¬í•­ ë“±ì„, **AI ê·¼ë¡œê°ë…ê´€**ì—ê²Œ ë°”ë¡œ ë¬¼ì–´ë³´ì„¸ìš”!")

# ==========================================
# 1. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (ê¸°ì–µ ì¥ì†Œ ë§Œë“¤ê¸°)
# ==========================================
# 'messages'ë¼ëŠ” ì €ì¥ì†Œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ìµœì´ˆ ì ‘ì† ì‹œ AIê°€ ê±´ë„¤ëŠ” ì¸ì‚¬ë§ì„ ì €ì¥ì†Œì— ë„£ìŠµë‹ˆë‹¤.
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "ë°˜ê°‘ìŠµë‹ˆë‹¤. ì•ˆì‚°ë„ì‹œê³µì‚¬ **AI ê·¼ë¡œê°ë…ê´€**ì…ë‹ˆë‹¤. ğŸ‘®â€â™‚ï¸\n\nì‘ì—… í˜„ì¥ì˜ ì•ˆì „ ê¸°ì¤€ì´ë‚˜ ë²•ì  ê³¼íƒœë£Œ ì‚¬í•­ ë“± ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."
    })

# ==========================================
# 2. ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— ë¿Œë¦¬ê¸°
# ==========================================
# ì €ì¥ì†Œ(messages)ì— ìˆëŠ” ëŒ€í™”ë¥¼ ìˆœì„œëŒ€ë¡œ êº¼ë‚´ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ==========================================
# 3. ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬
# ==========================================
if user_question := st.chat_input("ì§ˆë¬¸ ì˜ˆ: 2m ì´ìƒ ê³ ì†Œì‘ì—… ì‹œ ì•ˆì „ë‚œê°„ ì„¤ì¹˜ ê¸°ì¤€ì€?"):
    
    # (1) ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í™”ë©´ì— í‘œì‹œí•˜ê³  -> ì €ì¥ì†Œì— ì¶”ê°€
    with st.chat_message("user"):
        st.markdown(user_question)
    st.session_state.messages.append({"role": "user", "content": user_question})

    # (2) AI ë‹µë³€ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty() # ë‹µë³€ì´ ì¨ì§ˆ ë¹ˆ ê³µê°„
        full_response = ""
        
        with st.spinner("ë²•ë ¹ ë° ì§€ì¹¨ì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                model = genai.GenerativeModel('gemini-3-flash-preview')
                
                prompt = f"""
                ë‹¹ì‹ ì€ ëƒ‰ì² í•˜ê³  ì •í™•í•œ 'ëŒ€í•œë¯¼êµ­ ê³ ìš©ë…¸ë™ë¶€ ê·¼ë¡œê°ë…ê´€'ì´ì 'ì‚°ì—…ì•ˆì „ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë²•ì  ê·¼ê±°(ì‚°ì—…ì•ˆì „ë³´ê±´ë²•, ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²•, ì¬ë‚œì•ˆì „ë²•, ì´ì™€ ê´€ë ¨ëœ ì‹œí–‰ë ¹ê³¼ ê·œì¹™ ë“±)ë¥¼ ëª…í™•íˆ ë“¤ì–´ ë‹µë³€í•˜ì„¸ìš”.
                
                [ë‹µë³€ ì›ì¹™]
                1. ê·¼ê±° ì—†ëŠ” ë‹µë³€ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.
                2. ë²• ì¡°í•­(ì œëª‡ì¡° ì œëª‡í•­)ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•œë‹¤.
                3. í˜„ì¥ì—ì„œ ì‹¤ì²œí•´ì•¼ í•  'í•µì‹¬ ì¡°ì¹˜ì‚¬í•­'ì„ ìš”ì•½í•´ì¤€ë‹¤.
                4. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ë˜, ì „ë¬¸ê°€ë‹µê²Œ ë‹¨í˜¸í•˜ê³  ëª…í™•í•˜ê²Œ í•œë‹¤.

                ì‚¬ìš©ì ì§ˆë¬¸: {user_question}
                """
                
                response = model.generate_content(prompt)
                full_response = response.text
                
                # ë‹µë³€ í™”ë©´ ì¶œë ¥
                message_placeholder.markdown(full_response)
                
            except Exception as e:
                full_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                message_placeholder.error(full_response)

    # (3) AI ë‹µë³€ë„ ì €ì¥ì†Œì— ì¶”ê°€ (ê·¸ë˜ì•¼ ì•ˆ ì‚¬ë¼ì§)
    st.session_state.messages.append({"role": "assistant", "content": full_response})