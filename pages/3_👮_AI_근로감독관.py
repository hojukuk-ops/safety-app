import streamlit as st
import google.generativeai as genai

# [ì£¼ì˜] st.set_page_configëŠ” app.pyì—ì„œ ì„¤ì •í•˜ë¯€ë¡œ ìƒëµ

# API í‚¤ ì„¤ì •
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except:
    st.error("ğŸš¨ API í‚¤ ì˜¤ë¥˜: secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# í—¤ë”: AI ê·¼ë¡œê°ë…ê´€ í˜ë¥´ì†Œë‚˜ ì„¤ì •
# ==========================================
st.title("ğŸ‘® ì•ˆì‚°ë„ì‹œê³µì‚¬ AI ê·¼ë¡œê°ë…ê´€ (ì±—ë´‡)")
st.info("ì‚°ì—…ì•ˆì „ë³´ê±´ë²•, ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²•, ì¬ë‚œì•ˆì „ê¸°ë³¸ë²• ë“± ë³µì¡í•œ ë²•ë ¹ê³¼ ì´ì— ê·¼ê±°í•œ ì‘ì—… ê¸°ì¤€ ë“±ì„ AIì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!")

# ==========================================
# 1. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (ê¸°ì–µ ì¥ì†Œ ë§Œë“¤ê¸°)
# ==========================================
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ìµœì´ˆ ì ‘ì† ì‹œ ì¸ì‚¬ë§ ì €ì¥
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "ë°˜ê°‘ìŠµë‹ˆë‹¤. ì•ˆì‚°ë„ì‹œê³µì‚¬ **AI ê·¼ë¡œê°ë…ê´€**ì…ë‹ˆë‹¤. ğŸ‘®â€â™‚ï¸\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    })

# ==========================================
# 2. ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— ë¿Œë¦¬ê¸°
# ==========================================
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ==========================================
# 3. ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬
# ==========================================
if user_question := st.chat_input("ì§ˆë¬¸ ì˜ˆ: 2ì¢… ì‹œì„¤ë¬¼ ì •ê¸°ì•ˆì „ì ê²€ ì£¼ê¸°ëŠ”?"):
    
    # (1) ì‚¬ìš©ì ì§ˆë¬¸ í™”ë©´ í‘œì‹œ ë° ì €ì¥
    with st.chat_message("user"):
        st.markdown(user_question)
    st.session_state.messages.append({"role": "user", "content": user_question})

    # (2) AI ë‹µë³€ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty() # ë‹µë³€ì´ ì¨ì§ˆ ë¹ˆ ê³µê°„
        full_response = ""
        
        with st.spinner("ë²•ë ¹(ì‚°ì•ˆ, ì‹œì„¤, ê±´ì„¤, ì¬ë‚œ) ë° ë¬¸ë§¥ì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ğŸš¨ [ì‚¬ìš©ì ìš”ì²­] ëª¨ë¸ ìœ ì§€ (3.0 í”„ë¦¬ë·°)
                model = genai.GenerativeModel('gemini-3-flash-preview')
                
                # ğŸ”„ [ì—…ê·¸ë ˆì´ë“œ 1] ëŒ€í™” íë¦„(Context) ë§Œë“¤ê¸°
                # í™”ë©´ì— ë– ìˆëŠ” ì±„íŒ… ê¸°ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì„œ AIì—ê²Œ "ì´ê²Œ ì§€ê¸ˆê¹Œì§€ í•œ ì–˜ê¸°ì•¼"ë¼ê³  ì¤ë‹ˆë‹¤.
                conversation_history = ""
                for msg in st.session_state.messages:
                    role_name = "AI ê·¼ë¡œê°ë…ê´€" if msg['role'] == "assistant" else "ì‚¬ìš©ì"
                    conversation_history += f"{role_name}: {msg['content']}\n"

                # ğŸ“š [ì—…ê·¸ë ˆì´ë“œ 2] í”„ë¡¬í”„íŠ¸ ë³´ê°• (ì‹œíŠ¹ë²•, ê±´ì§„ë²•, ì¬ë‚œë²• ì¶”ê°€)
                prompt = f"""
                ë‹¹ì‹ ì€ ëƒ‰ì² í•˜ê³  ì •í™•í•œ 'ëŒ€í•œë¯¼êµ­ ê³ ìš©ë…¸ë™ë¶€ ê·¼ë¡œê°ë…ê´€'ì´ì 'êµ­í† ì•ˆì „ê´€ë¦¬ì› ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
                ì•„ë˜ì˜ [ì´ì „ ëŒ€í™” ê¸°ë¡]ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ [í˜„ì¬ ì§ˆë¬¸]ì— ëŒ€í•´ ì ì ˆí•œ ë²•ì  ê·¼ê±°ë¥¼ ë“¤ì–´ ë‹µë³€í•˜ì„¸ìš”.
                
                [ê²€í† í•´ì•¼ í•  ë²•ë ¹ ë²”ìœ„]
                1. **ì‚°ì—…ì•ˆì „ë³´ê±´ë²• (ì‚°ì•ˆë²•)**: ê·¼ë¡œìì˜ ì•ˆì „ ë° ë³´ê±´
                2. **ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²• (ì¤‘ì²˜ë²•)**: ê²½ì˜ì±…ì„ìì˜ ì•ˆì „ë³´ê±´ í™•ë³´ ì˜ë¬´
                3. **ì‹œì„¤ë¬¼ì˜ ì•ˆì „ ë° ìœ ì§€ê´€ë¦¬ì— ê´€í•œ íŠ¹ë³„ë²• (ì‹œíŠ¹ë²•)**: 1,2,3ì¢… ì‹œì„¤ë¬¼ì˜ ì•ˆì „ì§„ë‹¨ ë° ì ê²€
                4. **ê±´ì„¤ê¸°ìˆ  ì§„í¥ë²• (ê±´ì§„ë²•)**: ê±´ì„¤ê³µì‚¬ ì•ˆì „ê´€ë¦¬ê³„íšì„œ, í’ˆì§ˆê´€ë¦¬
                5. **ì¬ë‚œ ë° ì•ˆì „ê´€ë¦¬ ê¸°ë³¸ë²• (ì¬ë‚œì•ˆì „ë²•)**: êµ­ê°€ ê¸°ë°˜ ì‹œì„¤ ë° ì¬ë‚œ ëŒ€ì‘
                6. ìœ„ì— ì–¸ê¸‰í•œ ë²•ë ¹ë“¤ì˜ í•˜ìœ„ ë²•(ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ë“±)
                
                [ì´ì „ ëŒ€í™” ê¸°ë¡] (ë¬¸ë§¥ ì°¸ê³ ìš©)
                {conversation_history}

                [í˜„ì¬ ì§ˆë¬¸]
                {user_question}
                
                [ë‹µë³€ ì›ì¹™]
                1. ì§ˆë¬¸ì˜ ì„±ê²©ì— ë”°ë¼ ê°€ì¥ ì í•©í•œ ë²•ë ¹ì„ ì¸ìš©í•œë‹¤. (ì˜ˆ: ê±´ë¬¼ ê· ì—´ -> ì‹œíŠ¹ë²•, ê³µì‚¬ì¥ ì¶”ë½ -> ì‚°ì•ˆë²•)
                2. ë²• ì¡°í•­(ì œëª‡ì¡° ì œëª‡í•­)ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•œë‹¤.
                3. í˜„ì¥ì—ì„œ ì‹¤ì²œí•´ì•¼ í•  'í•µì‹¬ ì¡°ì¹˜ì‚¬í•­'ì„ ìš”ì•½í•´ì¤€ë‹¤.
                4. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ë˜, ì „ë¬¸ê°€ë‹µê²Œ ë‹¨í˜¸í•˜ê³  ëª…í™•í•˜ê²Œ í•œë‹¤.
                """
                
                response = model.generate_content(prompt)
                full_response = response.text
                
                # ë‹µë³€ í™”ë©´ ì¶œë ¥
                message_placeholder.markdown(full_response)
                
            except Exception as e:
                full_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                message_placeholder.error(full_response)

    # (3) AI ë‹µë³€ ì €ì¥ (ë‹¤ìŒ ëŒ€í™”ë¥¼ ìœ„í•´ ê¸°ì–µ)
    st.session_state.messages.append({"role": "assistant", "content": full_response})